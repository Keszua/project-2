
# Trzeba sciagnac i zainstalowac dockera 
https://www.docker.com/get-started

# oraz WSL2  (taki linux na windowsa)
https://docs.microsoft.com/pl-pl/windows/wsl/install-manual#step-4---download-the-linux-kernel-update-package

# zakladanie konta na:
https://hub.docker.com/signup


#-------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------
# Przykladowe kontenery
docker container run -d -p 8080:80 --name mynginx nginx:latest
docker container run -d -e POSTGRES_USER=user1 -e POSTGRES_PASSWORD=pass123 -p 5444:5432 postgres:latest


# tworzenie sieci i uruchomienie kontenera wordpresa z mySql
docker network create --driver=bridge skynet
docker container run -d -p 3308:3306 --name db -e MYSQL_DATABASE=exampledb -e MYSQL_USER=exampleuser -e MYSQL_PASSWORD=12345678 -e MYSQL_RANDOM_ROOT_PASSWORD=1 --network=skynet --restart=always mysql:5:7
#                                                 └ Jak ma sie nazywac baza                                                        └ wygeberuj automatycznei bespieczne haslo dla roota
docker container run -d -p 8080:80 -e WORDPRESS_DB_HOST=db:3306 -e WORDPRESS_DB_USER=exampleuser -e WORDPRESS_DB_PASSWORD=12345678 -e WORDPRESS_DB_NAME=exampledb --network=skynet  --restart=always wordpress:latest
#                                                          └ port besposredni (nie do lokalnego przekierowania)



#-------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------








# link do repo z kursu: 
https://github.com/pnowy/docker-course
#-------------------------------------------------------------------------------------------------
docker version
docker info       # liczba kontenerow i obrazow


docker            # wyswietli liste polecen

docker image pull nazwaObrau         # sciagniecie danego obrazu, bez uruchamiania
docker image pull nazwaObrau:mojTag  # sciagniecie danego obrazu + nadaj tag ale tez jakos koles sciagal odpowiednie wersje za pomocc tagu (film 18)
docker run
docker container run   # uruchomienie NOWEGO kontenera. Jezeli nie posiadamy obrazu, zostanie on sciagniety i uruchomiony
docker container run --publish 8080:80 --detach nginx  
#                      |       |    |    |      └ nazwa obrazu
#                      |       |    |    └ uruchomienie kontenera w tle
#                      |       |    └ port po stronie kontenera
#                      |       └ port, na ktorym kontener bedzie dostepny na naszym hoscie (zwykle localhost:8080)
#                      └ przekierowanie, -p [host-port:container-port]
#  zatrzymanie kontenera przez:  Ctrl+C

docker container run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -d --name=myName docker.elastic.co/elasticsearch/elasticsearch:6.5.4
#                     |                         |                                   |           |                                             |- wersja albo tag
#                     |                         |                                   |           |- nazwa obrazu
#                     |                         |                                   └ nazwa kontenera
#                     |                         └ przekazanie zmiennej srodowiskowej
#                     └[host-port:container-port]


# kontener z centosem:
docker run -it centos:8 bash
# aby naprawić instalację trzeba zrobić:
cd /etc/yum.repos.d/
sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*
sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*
yum update -y
yum install NetworkManager
# od teraz dzial polecenie:
nmcli -h


#  uruchom w trybie interaktywnym z terminalem (wyjscie komenda exit)
docker container run -it nginx bash 
docker container start -ai idkontenera
docker container exec -it idkontenera bash  #  odpalenie konsoli na dzialajacym kontenerze
docker attach  [id lub nazwa kontenera]     #  odpalenie konsoli na dzialajacym kontenerze. Przerywamy Ctrl+C (cos było że nie polecane)


docker stop idkontenera
docker container stop idkontenera

docker container ls     #  wyswietli liste kontenerow URUCHOMIONYCH
docker ps               #  po staremu 
docker container ls -a  #  wyswietli liste wszystkich kontenerow, czyli nie uruchominych tez
docker image ls         #  lista obrazow

docker container start idkontenera  #  uruchominie istniejacego kontenera
docker rm idkontenera               #  usowanie kontenera
docker system prune --all           #  usowanie WSZYSTKICH obrazów jednym poleceniem:


docker container logs nazwaKontenera
docker container logs nazwaKontenera -f # ciagla obserwacja (zablokuje CLI)

curl localhost:8080  # zwroci kod HTML strony
curl localhost:9200  # zwroci JSON (jezli mamy odpalony elastic)

# curl - taka przegladarka z linii komend
curl -H "Content-Type: application/json" -XPOST "http://localhost:9200/docker/image/1" -d "{ \"name\" : \"elasticsearch\"}"
curl localhost:9200/docker/_search

#  do obserwowania, co sie dzieje w kolejkach
docker run -d --name rabbit-in-the-hole -p 8081:15672 rabbitmq:3-managment
#  po wejsciu na przegladarce, mozna sie zalogowac L: guest  H: guest


docker container top idkontenera      #  obserwacja procesow
docker container inspect idkontenera  #  wyswietla pelna konfiguracje kontenera (w formacie JSON)
docker container stats                #  "live striming" ogolny status wszystkich uruchominych kontenerow


#  -------------------------------------------------------------------------------------------------
docker network ls 
docker network inspect nazwaSieci

#  tworzenie sieci:
docker network create --driver=bridge mojaNowaNazwaSieci

#  uruchomienie kontenera "nginx" w konkretnej sieci (tutaj nazwa sieci to: skynet)
docker container run -d --network=skynet nginx
docker network connect skynet first      #  podlaczenie do sieci, kontenera first
docker network disconnect bridge first   #  odpiecie kontenera od domyslnej sieci (bo teraz byly dwie sieci)

#  Usuwanie sieci:
#  w pierszej kolejnosci trzeba odpiac lub usunac kontenery

#  DNS
#  Film 17 (Docker od podstaw)
#  Trzeba sprawdzic IPAddress  (polecenie docker network inspect ...)
#  Endpoint informujacy o stanie serwisu: (w konsoli linuxa)
curl http://172.17.0.3:8080/actuator/health

#  do wywołania postów curlem:
curl -X POST http://localhost:3000/parametr


#  urzycie opcji link ... na przykladzie polaczenia do bazy MSQL
docker run --name wordpressdb -e MYSQL_ROOT_PASSWORD=wordpress -e MYSQL_DATABASE=wordpress -d mysql:5.7
docker run -e WORDPRESS_DB_PASSWORD=wordpress -d --name wordpress --link wordpressdb:mysql -p 80:80  wordpress:5-php7.2
#                                   |                   |                |           |        └ port zewnetrzny dla przegladarki
#                                   |                   |                |           └ wewnetrzny alias, domyslnia nazwa dla bazy danych to mysql
#                                   |                   |                └ nazwa kontenera
#                                   |                   └ nazwa kontenera
#                                   └ nazwa bazy danych


# konfiguracja PrestaShop z bazą przez zmienną środowiskową (nie przez link)
# create a network for containers to communicate
$ docker network create prestashop-net
# launch mysql 5.7 container
$ docker run -ti --name some-mysql --network prestashop-net -e MYSQL_ROOT_PASSWORD=admin -p 3307:3306 -d mysql:5.7
# launch prestashop container
$ docker run -ti --name some-prestashop --network prestashop-net -e DB_SERVER=some-mysql -p 8080:80 -d prestashop/prestashop
# UWAGA! Gdy zmienie nazwę bazy, to tez trzeba ta nazwe zmienic w DB_SERVER=some-mysql


Nazwa klepu: Karol_test
Imie: Karol
Nazwisko: M
Email: k.michalczyk@humansoft.pl
H 12345678

#  -------------------------------------------------------------------------------------------------
#  Budowanie obrazow

docker image history nazwaObrazu   # mozna podejzec, kiedy i z jakich warstwy zostal stworzony obraz
docker image inspect idKontenera   # wyswietla pelna konfiguracje obrazu (w formacie JSON)

#  nadawanie nowego tagu
docker image tag nazwa:zTagiem nazwaKontaDockerHub/nazwa
#                                                   |- nazwa z ewentualnym tagiem

#  wyslanie obrazu na wlasne repozytorium:
#  trzeba byc zalogowanym, te same dane co na https://hub.docker.com/ :
docker login 
docker image push nazwaKontaDockerHub/nazwaObrazu:zTagiem
docker logout #  jezli chcemy sie wylogowac 

#  pobranie ze swojego repo
docker image pull nazwaKontaDockerHub/nazwaObrazu:zEwentualnymTagiem

#  tworzenie obrazu na podstawie kontenera:
docker container commit idKontenera nazwaKontaDockerHub/nazwaObrazu:zTagiem



  #####                 #                     ###       #
   #   #                #                    #      #   #
   #   #   ###    ###   #  #   ###   # ###   #          #       ###
   #   #  #   #  #   #  # #   #   #  ##     ####   ##   #      #   #
   #   #  #   #  #      ##    #####  #       #      #   #      #####
   #   #  #   #  #   #  # #   #      #       #      #   #   #  #
  #####    ###    ###   #  #   ###   #       #     ###   ###    ###
#  -------------------------------------------------------------------------------------------------
#  Dockerfile
#  tworzenie kontenera z wykorzystaneim pliku Dockerfile
#  w filmie 21 koles pokazuje plik Dockerfile gdzie definiuje sie, jak przerobic i skonfigurowac obraz
https://docs.docker.com/engine/reference/builder/
#  trzeba bylo konsole otworzyc w folderze w ktorym jest plik Dockerfile
docker image build -t nowaNazwaObrazu:tag .
# po zbudowaniu, mozna go uruchomic: docker container run -d -p 8080:8080 --name=nazwaKontenera nowaNazwaObrazu:tag

#  Przykład pliku:
FROM node:10-slim
WORKDIR /app             #  Create app directory WORKDIR to tak jak RUN cd /app   Dla noda: /app   dla nginx: /usr/share/nginx/html

COPY package*.json ./    #   Kopiuje pliki Z lokalnego host DO obrazu. Inny przyklad: COPY package.json package-lock.json /code/

RUN npm install --only=production   #   RUN wykonuje komendę

COPY . .   #   Kopiuj wszystko z folderu, oprucz elementów zdefiniowanych   lub: COPY src /code/src

EXPOSE 3000  #  port do nasłuchu, w innym przykladzie dla node byl port:  8080

ENV NODE_ENV production  #   Zmienne srowowiskowe przekazane do obrazu

#   ENTRYPOINT [ "entrypoint.sh" ]  Gdy nie podamy Entrypoint, wywoła się polecenie domyślne: /bin/sh -c
#   "entrypoint.sh" - to plik, który powninen być obok Dockerfile
#   CMD ["trafik"] specyfikuje argument, jaki będzie przekazywany do ENTRYPOINTa
CMD ["node", "app.js"]     # w innym przykladzie:  CMD [ "npm", "start" ]

LABEL   #  - metadane do obrazu



  #     #         #
  #     #         #
  #     #   ###   #      #   #  ### ##    ###    ###
  #     #  #   #  #      #   #  #  #  #  #   #  #
   #   #   #   #  #      #   #  #  #  #  #####   ###
    # #    #   #  #   #  #   #  #  #  #  #          #
     #      ###    ###    ####  #  #  #   ###    ###
#--------------------------------------------------------------------------------------------------
#  Volumes
docker volume ls     #  wyświetl wszytkie volumeny
docker volume prune  #  usuwanie wszytkie volumeny


#  aby sprawdzić czy volumen jest podpięty, wywołac polecenie:
docker container inspect idKontenera
#  w "Mounts": [    powinien być "Type": "volume"  z jego nazwą (id)


# przykład ze strony https://adamtheautomator.com/docker-windows/
# Parametr --mount wymaga trzech argumentów; 
docker run --mount type=bind,source="E:/",target=/home/TEST -it alpine
#                  |         |            └ścieżka do katalogu docelowego. Ścieżka docelowa będzie dowiązaniem symbolicznym w kontenerze.
#                  |         └ścieżka do źródłowego katalogu hosta
#                  └typ montowania


#  aby do kontenera podpiąć istniejący wolumen:
docker container run -d --mount 'src=idVolumenu,dst=/appdata' -p 3000:3000 nazwaObrazu

#  starsza metoda podpinania volumenu, przez literę -v
docker container run -d -v idVolumenu:/appdata' -p 3000:3000 nazwaObrazu

#  uruchomienie kontenera i stworzenie volumenu z "ludzką" nazwą
docker container run -d --mount 'src=nazwa-volumenu,dst=/appdata' -p 3000:3000 nazwaObrazu

# przykład z filmu https://www.youtube.com/watch?v=p2PH_YPCsis&list=PLy7NrYWoggjzfAHlUusx2wuDwfCrmJYcs&index=12
docker run -v /home/mount/data:/var/lib/mysql/data
#              |                └ sciezka do kataogu w maszynie (wnętrze kontenera)
#              └ Host Volumes. Jezeli tego nie podam, doker wygeneruje losową nazwę: /var/lib/docker/volumes/random-hash/_data

# Sztuczka na kopiowanie volumenu:
docker container run --rm -it -v staraNazwa:/from -v nowaNazwa:/to alpine ash -c "cd /from; cp -av . /to"


# Tworzenie kopii zapasowej danych Jenkinsa z kontenera do hosta https://adamtheautomator.com/jenkins-docker/
docker cp <container id>:/path/in/container /path/in/host
# przyklad:
docker cp my-jenkins-1:/var/jenkins_home ~/jenkins_backup


#--------------------------------------------------------------------------------------------------
#  Bind mounnts
#  coś jak Volumes dla wersji developerskiej (starsze podejście)

#  uruchamiamy kontener z flagą -v
docker run -d -p 80:80 -v $(pwd):/usr/share/nginx/html nginx
#  w przypadku windowsa:
docker run -d -p 80:80 -v //c/User/przemek/data:/path/data
#  u mnie zadziałało tak: (w konsoli bash)
docker run -d -p 80:80 -v //d/Karolek/Docker/dockerfiles/nginx-simple:/usr/share/nginx/html nginx



  #####                 #
   #   #                #
   #   #   ###    ###   #  #   ###   # ###        ###    ###   ### ##   ####    ###    ###    ### 
   #   #  #   #  #   #  # #   #   #  ##          #   #  #   #  #  #  #  #   #  #   #  #      #   #
   #   #  #   #  #      ##    #####  #           #      #   #  #  #  #  #   #  #   #   ###   #####
   #   #  #   #  #   #  # #   #      #           #   #  #   #  #  #  #  ####   #   #      #  #    
  #####    ###    ###   #  #   ###   #            ###    ###   #  #  #  #       ###    ###    ### 
                                                                        #
#--------------------------------------------------------------------------------------------------
#  Docker compose
#  Definicja w pliku: docker-compose.yml  #  może być inna nazwa, ale będzie trzeba ją podać w komendzie

#  ogólny pos:
version: '3.7'

services:               # definicja kontenerów (odpowiednik docker container run)

  db:         # nazwa serwisu (np. "db" lub "elasticsearch" ), będzie to także DNS serwisu w sieci
    image: mysql:5.7    # nazwa obrazu którego użyć do uruchomienia kontenera (opcjonalny w przypadku użycia build)
    restart: always     # always-po wykryciu bledu, restartuj do skutku.
    environment:        # zmienne środowiskowe przekazywane do kontenera przy jego uruchomieniu
      # KEY: value
      # KEY2: value2
      MYSQL_PASSWORD: db_password
      MYSQL_RANDOM_ROOT_PASSWORD: '1'  # dla automatycznego generowania hasla  # lub MYSQL_ROOT_PASSWORD: somewordpress
      MYSQL_DATABASE: wordpress
      MYSQL_USER: db_user
      MYSQL_PASSWORD: db_password
    env_file:           # zmienne środowiskowe
      - a.env           # zmienne środowiskowe z pliku
    command:            # nadpisanie domyślnego polecenia kontenera/obrazu
    volumes:            # odpowiednik -v z docker run (wsparcie zarówno starszej jak i nowszej składni)
      - db_data:/var/lib/mysql  # lub - db-vol:/var/lib/mysql
  
  mywordpress:          # kolejny serwis (np: "wordpress")
    image: wordpress:latest
    container_name: mywordpess   # OPCJONALNIE
    #command: # OPCJONALNIE, zastepuje CMD z Dockerfile
    restart: always
    depends_on:         # okreslamy zależność pomiędzy kontenerami. Ten jest zależny od "db", czyli uruchomi się, jak ten poprzedni już będzie działał
      - db

    ports:
      - "8000:80"
    environment:
      WORDPRESS_DB_HOST: db:3306   # adres serwera i port. Adres przez DNS jest taką nazwą jak nazwa kontenera
      WORDPRESS_DB_USER: db_user
      WORDPRESS_DB_PASSWORD: db_password
    volumes:
      - wordpress-volume:/var/www/html

volumes:                # definicja wolumenu (docker volume create)
  db_data:              # przyklad z nazwa volumenu (pusta nazwa po dwukropku (chyba))
  wordpress-volume:

networks:               # definicja sieci (docker network create). Jesli tego nie podamy, to zostanie stworzona nowa siec


Przykałdowy wordpress
localhost:8000
Użytkownik: karol
H: karol


# Aby uruchomić:
# W konsoli upewnij sie ze jestes na dobrej sciezce i uruchom poleceniem:
docker-compose up       # tworzy i uruchamia. Jeśli korzytam z DockerDesktop lub RangerDesktop, moge urzyc skladni ze spacja:  docker compose
docker-compose up -d    # uruchomi kontenery w tle
# jeśli nie uruchomiony w trybie -d, to konczymy Ctrl+C
docker-compose start    # uruchomienie stworzonych kontenerów
# jeśli w trybie -d, zatrzymujemy komendą:
docker-compose stop     # mozna urzyc z nazwa konkretnego, pojedynczego kontenera
docker-compose down     # zatrzymanie i usunięcie wszytkich kontenerów i zależności
docker-compose down -v  # zatrzymanie i usunięcie wszytkich kontenerów i zależności + usun volumeny

docker-compose ps       # liste kontenerów
docker-compose top      # obserwacja procesów
docker-compose logs     # obserwacja logów


#--------------------------------------------------------------------------------------------------
#Przykład pliku dla App Service i MySQL z kursu: https://docs.microsoft.com/pl-pl/visualstudio/docker/tutorials/use-docker-compose

version: "3.7"

services:
  # docker run -dp 3000:3000 -w /app -v ${PWD}:/app --network todo-app -e MYSQL_HOST=mysql -e MYSQL_USER=root -e MYSQL_PASSWORD=secret -e MYSQL_DB=todos node:12-alpine sh -c "yarn install && yarn run dev"
  # Definiowanie App Service.
  app:                                 # Nazwa serwisu (dowolna, ale ona będzie aliasem sieciowym)
    image: node:12-alpine              # wpis usługi i obraz kontenera
    command: sh -c "yarn install && yarn run dev"   
    ports:
      - 3000:3000                      # zmigrowane polecenie: -p 3000:3000
    working_dir: /app                  # zmigruj katalog roboczy ( -w /app )
    volumes:
      - ./:/app                        # mapowanie woluminów ( -v ${PWD}:/app )  Docker Compose używa ścierzek względnych
    environment:                       # zmienne środowiskowe
      MYSQL_HOST: mysql
      MYSQL_USER: root
      MYSQL_PASSWORD: secret
      MYSQL_DB: todos

  # docker run -d --network todo-app --network-alias mysql -v todo-mysql-data:/var/lib/mysql  -e MYSQL_ROOT_PASSWORD=secret -e MYSQL_DATABASE=todos mysql:5.7
  # Definiowanie usługi MySQL
  mysql:                               # nazwa: mysql
    image: mysql:5.7                   # określ obraz do użycia.
    volumes:                           # zdefiniuj mapowanie woluminów.
      - todo-mysql-data:/var/lib/mysql # określić punkt instalacji w konfiguracji usług
    environment: 
      MYSQL_ROOT_PASSWORD: secret
      MYSQL_DATABASE: todos


volumes:                          
  todo-mysql-data: 

# Uruchamianie stosu aplikacji:
# Najpierw upewnij się, że nie są uruchomione żadne inne kopie aplikacji i bazy danych ( docker ps i docker rm -f <ids> ).
# Uruchom stos aplikacji przy użyciu polecenia docker-compose up  Dodaj -d flagę , aby uruchomić wszystko w tle. Alternatywnie możesz kliknąć prawym przyciskiem myszy plik Compose i wybrać opcję Utwórz dla VS Code bocznym.
docker-compose up -d

docker-compose logs -f       # Przyjrzyj się dziennikom za pomocą polecenia 
docker-compose logs -f app   # dziennik dla konkretnej usługi

docker-compose down          # zatrzymanie kontenerów i usówanie sieci


#--------------------------------------------------------------------------------------------------
# Przykład działającej konfiguracji PrestaShop:
version: '3.9'

services:
    prestashop_mysql:
        # image: mysql:5.7
        image: prestashop-db:5.7_3
        container_name: prestashop-db
        command: --default-authentication-plugin=mysql_native_password
        environment:
            MYSQL_DATABASE: prestashop
            MYSQL_ROOT_PASSWORD: admin
        volumes:
            # - ./.docker/data/mysql/:/var/lib/mysql
            # - ./.docker/logs/mysql/:/var/log/mysql
            - db_data:/var/lib/mysql
        ports:
            - 3307:3306
        networks:
            - presta-net
        
    prestashop:
        # image: prestashop/prestashop:1.7
        image: prestashop:1.7_3
        container_name: prestashop
        ports:
          - 8080:80
          - 2202:2202
        environment:
            DB_SERVER: prestashop_mysql
            MYSQL_HOST: mysql
            MYSQL_USER: root
            MYSQL_PASSWORD: admin
            MYSQL_DB: prestashop
        networks:
            - presta-net

networks:
  presta-net:
    external: false #needs to be created by other file
    driver: bridge
    name: prestashop-net

volumes:
  db_data:
    name: docker_test1_db_data


#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------

https://github.com/veggiemonk/awesome-docker

#  poczytac o Kubernetes znany też jako: K8s
https://kubernetes.io/


Instalacja Minikube : https://www.youtube.com/watch?v=X48VuDVv0do&t=453s   40:23


https://ihermes.humansoft.pl/login


#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
przez SSH:
docker1

VM 317

portainer.io
https://10.10.10.186:9443/#!/home
admin  
docker123


Nginx Proxy Manager
http://10.10.10.186:81/
m.zalecki@humansoft.pl
docker123


#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------

# jakiś filmik, jak stworzyć front w React i backend w Node.js  https://www.youtube.com/watch?v=-pTel5FojAQ

# W jednym folderze normalnie instaluje React
npx create-react-app forntend
# Robie drugi folder backend (na tym poziomie co cały React). 
# Wchodze do tego folderu, tam wywołuje 
npm init
# powatanie plik package.json, do kturego dopisuje zalezności (stare scripts usunąć):
{
  ...
  "dependencies": {
    "express": "4.16.3",
    "pg": "8.0.3",
    "cors": "2.8.4",
    "nodemon": "1.18.3",
    "body-parser": "*"
  },
  "scripts": {
    "dev": "nodemon",
    "start": "node index.js"
  }
}
# wywołujemy instalecję, aby zalezności się zainstalowały:
npm i

# Utwórz plik keys.js ze zmiennymi potrzebnymi dla kontenera
# Zawartość pliku:
module.exports = {
    pgUser: process.env.PGUSER,
    pgHost: process.env.PGHOST,
    pgDatabase: process.env.PGDATABASE,
    pgPassword: process.env.PGPASSWORD,
    pgPort: process.env.PGPORT,
}
# Utwórz plik index.js z prostym serwerem

#  uruchomienie serwera poleceniem:
npm run dev


# FRONT w package.json reacta do zalezności dopisujemy:   Film 9:20  https://www.youtube.com/watch?v=-pTel5FojAQ
{
  ...
  "dependencies": {
    ...
    "axios": "0.18.0",
    "react-router-dom": "4.3.1"
  },
}

# Projekt reacta odpalam przez:
npm run start


# Aby wsadzić projekt reacta  do kontenera, trzeba dodac plik (na poziomie .gitignore) Deckerfile.dev
# Zawartość pliku:   Film YT 18:30  https://www.youtube.com/watch?v=-pTel5FojAQ
FROM node:14.14.0-alpine
WORKDIR /app
COPY ./package.json ./
RUN npm i
COPY . .
CMD ["npm", "run", "start"]

# Buduje obraz projektu:
docker build -f Dockerfile.dev -t stylerhun/multi-client .

# Odpalam kontener:
docker run -it -p 4002:3000 --name=P1Front stylerhun/multi-client


# Teraz tworze kontener dla backendu, plik Dockerfile.dev jest podobny:
FROM node:14.14.0-alpine
WORKDIR /app
COPY ./package.json ./
RUN npm i
COPY . .
CMD ["npm", "run", "dev"]

# Buduje obraz projektu:
docker build -f Dockerfile.dev -t stylerhun/multi-server .

# Odpalam kontener:
docker run -it -p 4003:5000 --name=P1Back stylerhun/multi-server


#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
  #   #           #                                         #                           .
  #  #            #                                         #                           .
  # #     #   #   ####     ###    # ###   ####     ###    #####    ###     ###          .
  ##      #   #   #   #   #   #   ##      #   #   #   #     #     #   #   #             .
  # #     #   #   #   #   #####   #       #   #   #####     #     #####    ###          .
  #  #    #   #   #   #   #       #       #   #   #         #     #           #         .
  #   #    ####   ####     ###    #       #   #    ###       ##    ###     ###          .
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
KUBERNEST

# Proponowana wtyczk: YAML Language Support by Red Hat, with built-in Kubernetes syntax support 
# Następnie trzeba wejsc do ustawien tej wtyczki, znaleźć "Yaml:Schemas" -> Edit in settings.json
# dopisać:
    "yaml.schemas": {
        "kubernetes": "*.yaml"
    }

# chymura na google:
https://cloud.google.com/free/docs/gcp-free-tier


komendy na: https://kubernetes.io/docs/reference/kubectl/

kubectl version  # sprawdzenie, czy jest zainstalowany kubernetes i w jakiej wersjii
kubectl version --client --output=yaml    # 

# tworzenie podów zdefiniowanych w folderze k8s ( trzeba być na takim poziomie, żeby po wpisaniu ls widac było folder 'k8s')
kubectl apply -f k8s

╔══════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                     Kubernetes Cluster                                           ║
║ ╔════════════════════╗    ╔═════════════════════════════════════════════════════╗                ║
║ ║ Control plane      ║    ║ Data plane                                          ║                ║
║ ║ (mózg Kubernetesa) ║    ║ (worker nodes)    kubelet     Kube-proxy            ║                ║
║ ║                    ║    ║                     Container Runtime Engine        ║                ║  
║ ║  ┌──────────────┐  ║    ║  ┌─────────────────────────────┐    ┌─-----------┐  ║                ║ 
║ ║  │ Master       │  ║    ║  │ Node                        │    │ Node       │  ║                ║ 
║ ║  │──────────────│  ║    ║  │ ┌─────────────┐ ┌-----┐     │                    ║                ║ 
║ ║  │ETCD CLUSTER  │  ║    ║  │ │    POD      │   POD       │    │            │  ║                ║ 
║ ║  │kube-apiserver│  ║    ║  │ │┌-----------┐│ │     │     │                    ║                ║ 
║ ║ │Kube Controller│  ║    ║  │ ││ localhost ││             │    │            │  ║                ║ 
║ ║ │Manager        │  ║    ║  │ │ ┌─────────┐││ │     │     │                    ║                ║ 
║ ║  │kube-scheduler│  ║    ║  │ │││Kontener │ │             │    │            │  ║                ║ 
║ ║  └──────────────┘  ║    ║  │ │ └─────────┘││ │     │     │                    ║                ║ 
║ ║  ┌─────────┐       ║    ║  │ ││┌─────────┐ │             │    │            │  ║                ║ 
║ ║  │ Master  │       ║    ║  │ │ │Kontener │││ │     │     │                    ║                ║
║ ║  └─────────┘       ║    ║  │ ││└─────────┘ │             │    │            │  ║                ║
║ ║  ┌─────────┐       ║    ║  │ │└───────────┘│             │                    ║                ║
║ ║  │ Master  │       ║    ║  │ └─────────────┘ └-----┘     │    │            │  ║                ║
║ ║  └─────────┘       ║    ║  │                             │                    ║                ║
║ ║                    ║    ║  └─────────────────────────────┘    └------------┘  ║                ║
║ ╚════════════════════╝    ╚═════════════════════════════════════════════════════╝                ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════╝

Control plane - przyjmuje rozkazy od użytkownika, monitoruje cały stan, reaguje na wydażenia, decyduje, gdzie kontener ma byc uruchomiony
Worker odpowiada za uruchamianie kontenerów (tu beda dzialac nasze aplikacje)

Skalowanie ze względu na dochodzacych urzytkowników odbywa się przez dodawanie/odejmowanie POD'ów
Gdy skończy się przepustowość, a urzytkowników nadal przybywa, skalowanie odbedzie się przez Node



#            [LISTA]
kubectl get ┬ all            # pokaze pody, serwisy 
            ├ pods           # lista podów  z -A pokazuje ukryte systemowe
            ├ nodes          # lista wezlow
            ├ svc            # services  # lista serwisów z IP oraz portami
            ├ deployments    # aplikacja
            ├ ns             # namespaces
            ├ rc             # replicationcontrollers
            ├ rs             # replicaSet
            ├ job            # job, to taki jednorazowy pod
            ├ cronejob
            ├ secrets
            ├ ds             # DaemonSet
            └ endpoinds      # serwis tworzy taki endpoint przypisany do poda
kubectl get [LISTA] -o widge # troszke wiecej informccji
kubectl get [LISTA] -o yaml  # szczegóły
kubectl describe [LISTA] [NAME] # szczegóły konkretnego poda/noda.  NAME - to nazwa z wyświetlonego polecenia, no get pods
kubectl cluster-info         # informacje o klastrze

kubectl edit [LISTA] nazwa-elementu

watch -n 1 kubectl get pods  # stały podgląd 


# Doinstalowanie automatycznego podpowiadania
sudo apt update
sudo apt install bash-completion
# instrukcje do dalszego działania sa pod komendą:
kubectl completion -h
#jednorazowe podpowiadanie (na czas sesji)
source <(kubectl completion bash)



# na OVH działa usługa kubelet
systemctl status kubelet

# klucze i certyfikaty sa ukryte pod poleceniem
sudo docker ps | grep etcd



# pliki definicji .yaml  lub .yml
# zawsze zawiera 4 podstawowe pola:
apiVersion: v1  # wersja kubernetes
kind:           # rodzaj
metadata:
spec:

#--------------------------------------------------------------------------------------------------
  ####                   #
  #   #                  #
  #   #     ###      #####
  ####     #   #    #    #
  #        #   #    #    #
  #        #   #    #    #
  #         ###      #####
#--------------------------------------------------------------------------------------------------
Pod
┌───────────────────
apiVersion: v1                    # String
kind: Pod                         # String
metadata:                         #
  name: myapp-pod                 # \
  labels:                         # ├ Dictionary
    app: myapp                    # /
    tier: frontend                # etykieta do zgrupowania 
    #env: production
spec:
  containers:                     # List/Array
  - name: nginx-container         # pierwszy kontener. Dowolna nazwa
    image: nginx                  # nazwa z DockerHuba
    command: [ "sleep", "inf"]    # opcjonalnie. Te opcje "przytrzymują kontener przy życiu"
  - name: nginx                   # opcjonalnie kolejny kontener
    image: nginx
    ports:
      - containerPort: 80
  - name: ubuntu
    image: ubuntu:18.04
    command: [ "/bin/sh", "-c" ]
    args: [ "sleep 5; exit 1" ]   # to ustawienie ma zasymulować błędne zakończenie programu, Nie urzyzwac tego
    env:                          # [opcja] zmienne środowiskowe
    - name: LINK_MY               # mozna je podejzec poleceniem: kubectla logs nazwa uruchomionego poda
      value: "https://strefakursow.pl"
    - name: LICZBA_KURSOW
      value: "100" 
  restartPolicy: Always / Never / OnFailure  # [opcjonalnie] kiedy ma sie zretartować
└───────────────────

# stworzenie poda:   To polecenie również aktualizuje zmiany wprowadzine w pliku .yaml
kubectl create -f pod-definition.yml        # uruchomienie imperatywne

# Tworzenie poda w konsoli, bez pliku .yaml Tutaj pod z kontenerem ngix
kubectl run nginx --image=nginx

kubectl apply pod myapp-pod                 # uruchomienie deklaratywne poda (zwykle, gdy wprowadzimy zmiany w pliku .yaml)

kubectl delete pod myapp-pod                # kasowanie poda

kubectl exec -it nazwa-poda bash            # jak wejść do środka kontenera w podzie
kubectl exec -c nginx -it nazwa-poda bash   # gdy mamy kilka kontenerów

kubectl logs nazwa-poda                     # wyswietli logi   -f automatyczne odświerzanie
kubectl logs nazwa-poda -c nazwaKontenera   # wyswietli logi dla konkretnego kontenera



#--------------------------------------------------------------------------------------------------
   ####                    #                               ###              #  
   #   #                   #        #                     #   #             #
   #   #    ###    ####    #              ###     ####    #        ###    #####
   ####    #   #   #   #   #       ##    #   #        #    ###    #   #     #
   # #     #####   #   #   #        #    #        #####       #   #####     #
   #  #    #       ####    #   #    #    #   #   #    #   #   #   #         #
   #   #    ###    #        ###    ###    ###     ### #    ###     ###       ##
                   #
#--------------------------------------------------------------------------------------------------
Replica Set - przywraca uszkodzone kontenery. Dba o to, aby okreslona liczba podow dzialala. Rowniez pomaga w skalowaniu podow
Replication Controller - podobne narzedzie jak Replica Set, ale już nie rekomedowany.
ReplicaSet trzyma ostatnio działające DEPLOYMENTY przy podnoszeniu wersji za pomocą   kubectl set image deployment nazwa-deploymentu httpd=httpd:2.4 --record=true 
ReplicaSet może istnieć (kubectl get rs) i mieć 0 uruchomionych uszkodzonych kontenerów. Po to, aby przywrócić działóajaca wersję poleceniem   kubectl rollout undo deployment nazwa-deploymentu

Przykładowy plik ReplicaSet
┌───────────────────
apiVersion: apps/v1
kind: ReplicaSet  # ReplicationController
metadata:
  name: rs-webapp
  labels:
    app: myapp
    type: front-end

spec:
  replicas: 3                # ilosc podow, iloma ma sie opiekowac
  
  template:                  # jaki pod ma byc uruchomiony w ramach tego replicasetu
    metadata:                          # \
      labels:                          # |
        app: myapp                     # |
    spec:                              # ├ Zawartosc taka jak w Pod
      containers:                      # |
      - name: webapp                   # |
        image: k8smaestro/web-app:1.0  # /
        #ports
        #- containerPorts: 80
  selector:                  # jakimi konkretnie podami ma sie zaopiekowac (chyba zamiast template?)
    matchLabels:             # matchLabels albo matchExpressions
      type: front-end
      tier: front-end        # etykieta do grupowania. (To tylko na kursie Udemy)
      app: myapp             # tu odajemy nazwe, jaka jest w pliku definujacym poda:
                              ┌────────────────────────┐      
                              │ #pod-definition.yml     \    
                              │ apiVersion: v1           \    
                              │ kind: Pod                 \   
                              │ metadata:                  \ 
                              │   name:  myapp-pod          │ # (to tylko na kursie Udemy)
                              │   labels:                   │
                              │     app: myapp   <---       │
                              │     tier: front-end         │ # (to tylko na kursie Udemy)
                              └─────────────────────────────┘

# stworzenie Repliki
kubectl create -f rc-definition.yml

# sprawdzenie istniejących replik:
kubectl get rc

# przeładowanie pliku
kubectl replace -f rc-definition.yml

# przeskalowanie ilosci replik
kubectl scale --replicas=6 -f rc-definition.yml       # lub:
kubectl scale replicaset myapp-replicaset --replicas=2 
kubectl scale rs --replicas=6 myapp-replicaset 
#             └type           └name


# edytowanie (u mnie stacjonarnie nie zadzialalo)
kubectl edit replicaset myapp-replicaset


# usuwanie
kubectl delete replicaset myapp
kubectl delete replicaset rs-webapp
kubectl delete -f rc-definition.yml


#--------------------------------------------------------------------------------------------------                                          
   #####                    #                                                    #  
    #   #                   #                                                    #
    #   #    ###    ####    #        ###    #    #   ### ##     ###    ####    #####
    #   #   #   #   #   #   #       #   #   #   #    #  #  #   #   #   #   #     #
    #   #   #####   #   #   #       #   #    # #     #  #  #   #####   #   #     #
    #   #   #       ####    #   #   #   #     #      #  #  #   #       #   #     #
   #####     ###    #        ###     ###     #       #  #  #    ###    #   #      ##
                    #                       #
#--------------------------------------------------------------------------------------------------                                          
Deployment - "spina" w całosc nasza aplikację (troszkę jak docker-compose). 
Możemy za jego pomoca skalować, podnosić wersję, cofac się.
Stworzenie deployment - automatycznie stworzy ReplicaSet
╔═════════════════════════╗ 
║  Deployment             ║ 
║  ┌───────────────────┐  ║ 
║  │ ReplicaSet        │  ║ 
║  │ ┌─────────────┐   │  ║ 
║  │ │  POD        │   │  ║ 
║  │ │ ┌─────────┐ │   │  ║ 
║  │ │ │Kontener │ │   │  ║ 
║  │ │ │ <app>   │ │   │  ║ 
║  │ │ └─────────┘ │   │  ║ 
║  │ └─────────────┘   │  ║ 
║  └───────────────────┘  ║ 
╚═════════════════════════╝ 

┌───────────────────
apiVersion: apps/v1          
kind: Deployment             
metadata:                   
  #namespace: webapp-namespace
  name: deployment-moja-nazwa       
  labels:                   
    app: k8smaestro-webapp  
spec:                       
  replicas: 3  
  template:                 
    metadata:
      labels:
        app: k8smaestro-webapp         # na podstawie tych etykiet, wiadomo ktore pody naleza do jakich deploymentow
        #name: app-2048
    spec:
      containers:
      - name: webapp                   # obraz bazowy
        image: k8smaestro/web-app:1.0
        #- image: k8smaestro/2048
        #imagePullPolicy: Always       # polityka pobierania obazu na klaster. Always - zawsze pobiera obraz
        #name: app-2048
        #ports:                        # dodana informacja o porcie, gdy konfigurujemy Services
        #- containerPort: 80
  selector:  
    matchLabels:
      app: k8smaestro-webapp           # na podstawie tych etykiet, wiadomo ktore pody naleza do jakich deploymentow
└───────────────────        


# stworzenie/uruchomienie nowego deploymentu
kubectl create -f deployment-def.yml


# edycja działajacego deploymentu:
kubectl set image deployment/nazwa-deploymentu ubuntu=ubuntu:20.04
kubectl set env deployment/nazwa-deploymentu -c ubuntu SLEEP_TIME=110


# kasowanie
kubectl delete -f deployment-def.yml
kubectl delete nazwa-deploymentu  

# kasowanie wszystkiego
kubectl delete deployment --all

#--------------------------------------------------------------------------------------------------
   ####            #       #                         #  
   #   #           #       #                         #
   #   #    ###    #       #        ###    #   #   #####
   ####    #   #   #       #       #   #   #   #     #
   # #     #   #   #       #       #   #   #   #     #
   #  #    #   #   #   #   #   #   #   #   #   #     #
   #   #    ###     ###     ###     ###     ####      ##
#--------------------------------------------------------------------------------------------------
# Rollout and Versioning
# skalowanie

kubectl scale deployment voting-app-deploy --replicas=2

kubectl set image deployment nazwa-deploymentu httpd=httpd:2.4 --record=true  # przykładowa zmiana wersji kontenera podczas działania 
kubectl rollout undo deployment nazwa-deploymentu   # cofnięcie do porzedniej wersji (przed set image). wydaje mi się, że wcześniej trzeba dodać --record=true


kubectl rollout status deployment/myapp-deployment
kubectl rollout history deployment/myapp-deployment
kubectl rollout history deployment myapp-deployment  # na sterfie kursów, zapis rozdzielony spacją

# Aby zmienić wersję, trzeba wskazac na nowy kontener w:
spec:                       
  template:                 
    spec:
      containers:
        image: k8smaestro/web-app:1.1  <----


kubectl apply -f deployment-definiton.yml        
# drugi, niezalecany sposób:
kubectl set image deployment/myapp-deployment nginx=nginx:1.9.1 --record=true
#                                                                 └tylko, gdy chcemy, zeby się zapisywała i odczytywała hostoria poprzez rollout

# Rollback:  film 35 ok 10:00 (Kubernetes for the Absolute Beginners - Hands-on)
kubectl rollout undo deployment/myapp-deployment
kubectl rollout status deployment/myapp-deployment
kubectl rollout status deployment.app/myapp-deployment
kubectl rollout history deployment/myapp-deployment
kubectl rollout undo deployment/myapp-deployment           # przywrócenie poprzedniej wersji. Przydatne najbardziej, gdy wprowadzimy złą wersję i wywali błąd przy próbie wdrożenia (zastąpienia)


#--------------------------------------------------------------------------------------------------
   #   #             #                               #
   ##  #             #                               #       #
   ##  #    ###    #####   #     #    ###    # ###   #  #         ####     ####
   # # #   #   #     #     #     #   #   #   ##      # #    ##    #   #   #   #
   #  ##   #####     #     #  #  #   #   #   #       ##      #    #   #   #   #
   #  ##   #         #     # # # #   #   #   #       # #     #    #   #    ####
   #   #    ###       ##    #   #     ###    #       #  #   ###   #   #       #
                                                                          ####
#--------------------------------------------------------------------------------------------------
Networking
# film 37 (Kubernetes for the Absolute Beginners - Hands-on)
# Kazdy pod otrzymuje swój adres IP: 10.244.0.2, 10.244.0.3 itd
# Wszsytkie pody na naszym lokalnym kompie, widziane są przez chmórę: 10.244.0.0

# Narzędzia do konfiguracji sieci:
Cisco, cilium, flannel Vilmer, vmware NSX, Psyllium, Big Cloud fabric, Kalikow



#--------------------------------------------------------------------------------------------------
    ###
   #   #                              #
   #        ###    # ###   #     #          ###     ###     ###
    ###    #   #   ##      #     #   ##    #   #   #   #   #
       #   #####   #        #   #     #    #       #####    ###
   #   #   #       #         # #      #    #   #   #           #
    ###     ###    #          #      ###    ###     ###     ###
#--------------------------------------------------------------------------------------------------
Services
# film 38 (Kubernetes for the Absolute Beginners - Hands-on)
# Usługi umożliwiają komunikację między róznymi komponentami w ramach aplikacji i po za nią
# My łączymy się za pomocą asrestu i portu, a Service, ten port przełaczy z IP konkretnego Poda

Service Types:
 - ClusterIP (domyślnie) - Wystawia serwis poprzez wewnętrzny adres IP w klastrze. W ten sposób serwis jest dostępny tylko wewnątrz klastra.
 - NodePort - Wystawia serwis na tym samym porcie na każdym z wybranych węzłów klastra przy pomocy NAT. W ten sposób serwis jest dostępny z zewnątrz klastra poprzez <NodeIP>:<NodePort>. Nadzbiór ClusterIP.
 - LoadBalancer - Tworzy zewnętrzny load balancer u bieżącego dostawcy usług chmurowych (o ile jest taka możliwość) i przypisuje serwisowi stały, zewnętrzny adres IP. Nadzbiór NodePort.
 - ExternalName - Przypisuje Service do externalName (np. foo.bar.example.com), zwracając rekord CNAME wraz z zawartością. W tym przypadku nie jest wykorzystywany proces przekierowania ruchu metodą proxy. Ta metoda wymaga kube-dns w wersji v1.7 lub wyższej lub CoreDNS w wersji 0.0.8 lub wyższej.


#--------------------------------------
NodePort
#                                     ╔════════════════════════════════════════╗ 
#                                     ║        192.168.1.2                     ║
# mój laptop                          ║─────┐    ┌────────┬──┐    ┌──┬───────┐ ║
# curl http://192.168.1.2:30008 ----> ║30008│ -->│Service │80│ -->│80│    POD│ ║
#   Zakres: 30000 - 32767             ║─────┘    └───────────┘    │10.244.0.2│ ║
#                                     ║ Node                      └──────────┘ ║
#                                     ╚════════════════════════════════════════╝ 
#                                     nodePort            port     targetPort
┌───────────────────
apiVersion: v1          
kind: Service
metadata:                   
  name: myapp-service     # dowolna nazwa
  #labels:                #─┬─ dane takie, jak w "Deployment" w metadata.labels
    #name:                # │  żeby nasz serwis wiedział, do jakiego kontenera się przypiąć
    #app:                 #─┘
spec:
  ┌─────────── #opcja 1 - ClusterIP (domyślnie)
  type: ClusterIP
  ports:
  - targetPort: 80
    port: 80
  └───────────
  ┌─────────── #opcja 2 - NodePort
  type: NodePort
  ports:
  - targetPort: 80
    port: 80
    nodePort: 30008
  └───────────
  ┌─────────── #opcja 3 - LoadBalancer
  type: LoadBalancer
  ports:
  - targetPort: 80
    port: 80
    nodePort: 30008
  └───────────
  ┌─────────── #opcja 4 - przykład serwisu ze Strefy Kursów. koles nie podaje .type, tylko .protocol
  ports:
  - port: 80
    protocol: TCP             # jakiego typu protokół
  └───────────

  selector:  
    app: myapp       #─┬─ dane takie, jak w "Pod" w sekcji metadata.labels
    type: front-end  #─┘ 
└───────────────────

#--------------------------------------


# ustawienie portu do nasluchu:
kubectl expose deployment strefakursow-nginx --type=NodePort --port=8080

kubectl expose deployment deployment-2048 -n game

#--------------------------------------
# tworzenie servisu
kubectl creatae -f service-definition.yml
kubectl apply -f service-definition.yml

# pobireanie informacji o uruchomionych serwisach
kubectl get services

# pobranie adresu url w minikube (film 39)
minikube service myapp-service --url

# jeżeli istnieje serwis, powinno udac sie pobrac strone (nie wiem skąd ten adres)
curl http://192.168.1.2:30008


# W przykładzie, w Deployment, trzeba dopisać:
spec.template.spec.containers:
                   - name: ...
                     ports:               # dodana informacja o porcie
                     - containerPort: 80


#--------------------------------------------------------------------------------------------------
   #   #
   ##  #
   ##  #    ####    ### ##     ###     ###    ####     ####     ###     ###
   # # #        #   #  #  #   #   #   #       #   #        #   #   #   #   #
   #  ##    #####   #  #  #   #####    ###    #   #    #####   #       #####
   #  ##   #    #   #  #  #   #           #   ####    #    #   #   #   #
   #   #    ### #   #  #  #    ###     ###    #        ### #    ###     ###
                                              #
#--------------------------------------------------------------------------------------------------
Namespace - taki "wirtualny klaster" w ramach tego samego fizycznego klastra
Rodzaje namespace: Pod, ReplicaSet, Deployment, Service, itp...
Domyślnie trafia on do namestace default
Gdy tworzony jest Service, twory sie wpis w DNS:
<service-name>.<namespace-name>.svc.cluster.local


┌───────────────────
apiVersion: v1          
kind: Namespace
metadata:                   
  name: webapp-namespace  # dowolna nazwa
└───────────────────

kubectl get ┬ namespaces                   # lista przestrzeni nazw
            ├ ns                           # skrócony zapis
            ├ pods -n webapp-namespace     # jakie pody naleza do tej przestrzeni nazw
            └ all -n webapp-namespace      # wszystkie elementy przypisane do danej przestrzeni nazw


kubectl apply -f nazwaPliku.yaml           # zwykłe uruchomienie
kubectl apply -f nazwaPliku.yaml -n nazwaNamespace    # uruchomienie w podanej przestrzeni nazw

# kasowanie namespace
kubectl delete ns nazwaNamespace






#--------------------------------------------------------------------------------------------------
    #####             #    
        #             #
        #     ###     ####
        #    #   #    #   #
        #    #   #    #   #
    #   #    #   #    #   #
     ###      ###     ####
#--------------------------------------------------------------------------------------------------
JOB - taki pod, uruchomiony raz. Nie bedzie ponownie uruchamiany.
# Prosyt job, liczący od 10 w dóły:
┌───────────────────
apiVersion: batch/v1
kind: Job
metadata: 
  name: strefakursow-odliczanie
spec:
  ttlSecondsAfterFinished: 10  # [opcjonalnie*] po 10 sekundach, powinien się automatycznie usunąć
  template:
    metadata:
      name: odliczanie
    spec:
      containers:
      - name: container-odliczanie
        image: centos:7
        command:
        - "bin/bash"
        - "-c"
        - "for i in 9 8 7 6 5 4 3 2 1 ; do echo $i ; done"
      restartPolicy: Never    
└───────────────────
# uruchomienie:
kubectla apply -f ./nazwa-pliku.yaml

# Aby działało autowyłącznie, trzeba je aktywować poleceniem:
minikube --feature-gates="TTLAfterFinished=true"


# Job, który ma dla nas pobrac coś z YT:
┌───────────────────
apiVersion: batch/v1
kind: Job
metadata:
  name: strefakursow-yt-pobranie
spec:
  template:
    metadata:
      name: yt-pobranie
    spec:
      restartPolicy: Never
      containers:
      - name: yt-download
        image: wernight/youtube-dl
        # pierwszy sposob
        #command: ["youtube-dl", "adres_ktory_chcemy-pobrac_https://www.youtube.com/watch?v=dkfjdkjfk"]
        # Drugi sposob. Wywołana aktualizacja wtyczki
        command:
        - "/bin/bash"
        - "-c"
        - "pip install -U youtube-dl; youtube-dl https:/youtube.com/watch?v=dfjkfjdk"


apiVersion: batch/v1
kind: Job
metadata: 
  name: strefakursow-yt-pobranie
spec:
  template:
    metadata:
      name: yt-pobranie
    spec:
      restartPolicy: Never        
      containers:
      - name: yt-download
        image: wernight/youtube-dl
        # pierwszy sposob
        #command: ["youtube-dl", "adres_ktory_chcemy-pobrac_https://www.youtube.com/watch?v=dkfjdkjfk"]
        # Drugi sposob. Wywołana aktualizacja wtyczki
        # command:
        # - "/bin/bash"
        # - "-c"
        # - "pip install -U youtube-dl; youtube-dl https:/youtube.com/watch?v=dfjkfjdk"
        # Trzeci sposób:
        command:
        - "/bin/sh"
        - "-c"
        - "youtube-dl -n --cookies /cookies.txt https://youtu.be/zAPjjx05Y3k"
└───────────────────




#    ███                            █████           █    
#   █   █                               █           █
#   █       █ ███    ███    ████        █    ███    ████
#   █       ██      █   █   █   █       █   █   █   █   █
#   █       █       █   █   █   █       █   █   █   █   █
#   █   █   █       █   █   █   █   █   █   █   █   █   █
#    ███    █        ███    █   █    ███     ███    ████


# Job, który ma się wykonać o określonej porze
┌───────────────────
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: strefakursow-cron
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: strefakursow-pogoda-cron
            image: ubuntu:18.04
            command:
            - "/bin/bash"
            - "-c"
            - "apt-get update > /dev/null; apt-get install curl -y > /dev/null; curl -s http://wttr.in/Radom"
#                                                                └ od razu potwierdz  └ silent dla error messages
└───────────────────

# uruchomienie:
kubectl create -f nazwaPliku.yaml

# podgląd logów (oczywiście trzeba zdobyć id aktualnie uruchomionego poda)
kubectl logs job.batch/strefakursow-cron-27516178

# kasowanie:
kubectl delete cronjob strefakursow-cron


#--------------------------------------------------------------------------------------------------
#                  █
#                  █
#  █     █   ███   █      █   █  ███ ██    ███    ███
#  █     █  █   █  █      █   █  █  █  █  █   █  █
#   █   █   █   █  █      █   █  █  █  █  █████   ███
#    █ █    █   █  █   █  █   █  █  █  █  █          █
#     █      ███    ███    ████  █  █  █   ███    ███
#--------------------------------------------------------------------------------------------------
# Przykład z filmu [5:00] 5_4 Zmienne środowiskowe i wolumeny w podach (Kurs Kubernetes od podstaw - zarządzanie i automatyzacja kontenerów )
# 
┌───────────────────
apiVersion: v1
kind: Pod
metadata:
  name: ubuntu-strefakursow-env
spec:
  containers:
  - name: ubuntu-once
    env:
    - name: LINK_MY
      value: "https://strefakursow.pl"
    - name: LICZBA_KURSOW
      value: "20"
    volumeMounts: 
    - mountPath: /mntvol          # informacja, w jakim miejscu ma zostać zamontowany
      name: volume-no1            # nazwa musi być taka sama jak w 'volumes'
    image: ubuntu:18.04
    command:
    - "/bin/bash"
    - "-c"
    - "env; echo  ; for (( i=1 ; $i<=$LICZBA_KURSOW ; i++ )); do echo 'To jest pozycja numer: ' $i >> /mntvol/logs.test; done "
    # to co wypisze ten kontener, ma zapisać w pliku /mntvol/logs.test
    # następnie, ten plik jest podpięty do volumenu
    # aby kontener nie wyłaczyl się, możemy dodać do linni komend: sleep inf

    # drugi kontener
  - name: ubuntu-work
    image: ubuntu:18.04
    volumeMounts:
    - mountPath: /strefakursow
      name: volume-no1
    command:
    - "/bin/bash"
    - "-c"
    - "sleep inf"

  restartPolicy: Never
  volumes:                        #     volumen
  - name: volume-no1              #
    hostPath:                     # Jest kilka typów wolumenów. Tutaj skorzystamy z lokalnego storage na naszym danym nodzie
      path: /srv/persistent/
      type: DirectoryOrCreate     # Directory -musi istnieć.   DirectoryOrCreate -jeśli nie ma, to go stworzy. Więcej o typach: https://kubernetes.io/docs/concepts/storage/volumes/
└───────────────────

# UWAGA! Przed uruchominieniem tego pliku, trzeba dla volume stworzyć folder /srv/persistent/
# Tworzenie ręcznie:
# 1. Wejdz na minikube
minikube ssh
# 2. stwórz folder
sudo mkdir -p /stv/persistent/
# 3. wyjdz z minikube
exit


#--------------------------------------------------------------------------------------------------
#   ███                                 █  
#  █   █                                █
#  █       ███    ███   █ ███   ███   █████
#   ███   █   █  █   █  ██     █   █    █
#      █  █████  █      █      █████    █
#  █   █  █      █   █  █      █        █
#   ███    ███    ███   █       ███      ██
#--------------------------------------------------------------------------------------------------
#  pody, które generują jakieś hasła
┌───────────────────
apiVersion: v1
kind: Secret
metadata:
  name: strefa-secret                  # *1v
data:
  user: "cm9vdA=="
  pass: "VGFqbmVIYXNsbw=="             # *2v
stringData:                   # sekcja jawnych danych (nie szyfrowane)
  jawne: "Dane nie zaszyfrowane"
  ip: "192.168.2.1"
└───────────────────

# generowanie szyfrowanych danych w linuxie
echo -n "root" | base64

# Uruchomienie 
kubectl apply -f nazwaPliku.yaml

# podgląd
kubectl get secrets

# podgląd wszystkich
kubectl get secrets --all-namespace

# podglad naszego secret
kubectl describe secret nazwaNaszegoSecreta
# bedzie tu informacja podana w bajtach


# przykładowy Pod, korzsytający z naszych secretów
┌───────────────────
apiVersion: v1
kind: Pod
metadata:
  name: database-with-volume
spec:
  containers:
  - name: strefakursow-db-vol
    image: mysql
    volumeMounts:
    - name: dbconnection               # *3v
      mountPath: "/root/secrets"
      readOnly: true                   # ustawienie tylko odczytu
    env:
      - name: MYSQL_ROOT_PASSWORD
        valueFrom:
          secretKeyRef:
            name: strefa-secret        # *1^
            key: pass                  # *2^
  volumes:
  - name: dbconnection                 # *3^
    secret:
      secretName: strefa-secret
└───────────────────


#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
Kopiowanie plików
┌───────────────────
apiVersion: apps/v1
kind: Deployment
metadata:
  name: http-strefakursow
  labels:
    app: httpd-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: http-app
  template:
    metadata:
      labels:
        app: http-app
    spec:
      containers:
      - name: http
        image: httpd
        ports:
        - containerPort: 80
└───────────────────

# kopiowanie pliku:
kubectl cp index.html http-strefakursow-745758289-59mlr:/usr/local/apache2/htdocs/

# kopiowanie katalogu:
kubectl cp ../5_7 http-strefakursow-745758289-59mlr:/usr/local/apache2/htdocs/

#--------------------------------------------------------------------------------------------------
Statyczne Pody - czyli takie, które zawsze są dostępne (zawsze wuruchominone) jak kontenery systemowe
Filmin 6_7 Kurs Kubernetes od podstaw - zarządzanie i automatyzacja kontenerów. Statyczne Pody
Uruchamiane przez DaemonSet
/etc/kubernetes/manifests


#--------------------------------------------------------------------------------------------------
#  █████                █
#  █                    █               █       
#  █      █   █  ████   █  █   ███          ███ 
#  ████   █   █  █   █  █ █   █   █    ██  █   █
#  █      █   █  █   █  ██    █         █  █████
#  █      █   █  █   █  █ █   █   █     █  █    
#  █       ████  █   █  █  █   ███   █  █   ███ 
#                                     ██        
#--------------------------------------------------------------------------------------------------
Funkcje

Etykiety
# nadanie etykiety
kubectl label nazwaNoda nazwaChybaPoda test=true  
#                                      └ nasz label, zawierajacy klucz:wartość
#Pobranie etykiet
kubectl get nodes --show-labels

# Mozna skorzytac z etykiety:
# W przykładzie w kind: DaemonSet
# Automatyczne uruchamianie wszystkich podów, oznaczonych labelką. Trzeba dodać ta labelkę do:
spec.template.spec.nodeSelector:
                     test: "true"

#--------------------------------------------------------------------------------------------------
Init 
# Coś, co ma się wykonać przed uruchomieniem głównego kontenera. Np: podłączenie bo bazy, ściagnij plik > rozpakuj i dopiero uruchom
# Init dopiuje się w:
spec.template.spec.initContainers:
                   - name: unzip
                     image: garthk/unzip
                     command: [ "unzip", "/www/repo.zip", "-d", "/www/repo"]
                     volumeMounts:
                     - mountPath: /www
                       name: http-content
                   - name: clear
                     image: ubuntu
                     command: [ "sh", "-c", "rm -f /www/repo.zip" ]
                     volumeMounts:
                     - mountPath: /www
                       name: http-content

#--------------------------------------------------------------------------------------------------
Port-forward

kubectl port-forward nazwaUruchomionegoPoda 8080:80
# W odpowiedzi dostaniemy: Forwardng from 127.0.0.1:8080 -> 80 
# Będzie można zobaczyć wynik w przeglądarce 


# jakieś narzędzie
kubectl run -it --image=arunvelsriram/utils utils-container bash 

# ustawienie portu do nasluchu:
kubectl expose deployment hello-minikube --type=NodePort --port=8080


#--------------------------------------------------------------------------------------------------
#  █     █
#  ██   ██   █                                                       █
#  █ █ █ █        ███   █ ███   ███    ███    ███   █ ███  █     █        ███    ███    ███
#  █  █  █  ██   █   █  ██     █   █  █      █   █  ██     █     █  ██   █   █  █   █  █
#  █     █   █   █      █      █   █   ███   █████  █       █   █    █   █      █████   ███
#  █     █   █   █   █  █      █   █      █  █      █        █ █     █   █   █  █          █
#  █     █  ███   ███   █       ███    ███    ███   █         █     ███   ███    ███    ███
#--------------------------------------------------------------------------------------------------
Microservices  # film 44 (Kubernetes for the Absolute Beginners - Hands-on)

Tworzenie serwisu do głosowania

# tworzymy kontener z redisem, port 6379 
docker run -d --name=redis redis
# tworzymy kontener z bazą danych, port 5432
docker run -d --name=db postgres:9.4
# plikacj Web dla frontu, na której jest formulaz do głosowania (napisany w Pythonie), port 80
docker run -d --name=vote -p 5000:80 --link redis:redis  voting-app
# aplikacja do wyswietlanai wyników (napisana w node.js), port 80
docker run -d --name=result -p 5001:80 --link db:db  result-app
# aplikacja która będzie zbierała głosy i zapisywała ja w bazie (napisana w .NET)
docker run -d --name=worker --link db:db --link redis:redis  worker

# kroki do osiągniecia celu:
1. Deploy PODs
2. Create Services (ClusterIP)
  1. redis
  2. db
3. Create Services (NodePort)
  1. voting-app
  2. result-app

# sprawdzenie czy się utworzył:
kubectl get pods,svc

# utworzenie tunelu, aby sprawdzić przez stronę, czy coś widać (w CMD w trybie administratora):
minikube service voting-service --url
# u mnie nie zadziałało











#--------------------------------------------------------------------------------------------------
# szyfrowanie haseł:
kubectl create secret generic pgpassword --from-literal PGPASSWORD=12345test

# odczyt tokenów z hasłami:
kubectl get secret

# Pogubiłem się na Filmie YT 17:20 https://www.youtube.com/watch?v=OVVGwc90guo
# Nie znalazłem linku instalacyjnego, takiego jak koles z filmu.

kubectl get pv

kubectl delete -f k8s




#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
# Dzialajacy przyklad.
# Zakladam, ze mam uruchomiony minikube.
# W dowolnym folderze. Tworze plik 'all-in-one.yml' z zawartoscią poniżej (oczywiscie nazwa dowolna)
# Z poziou tego folderu odpalam sobie konsole (np git bash) i wywołuje polecenia
kubectl apply -f all-in-one.yml
  #jeżeli wyskoczy blad "Unable to connect to the server..." to pewnie trzeba odpalic minikube: minikube start
kubectl proxy

# Dostęp do Podów przez przeglądarkę: 
http://localhost:8001/api/v1/namespaces/game-2048/services/http:service-2048:/proxy/

# Aby sprawdzic wszystkie odpalone "serwisy/usługi"? zwiazane z 
kubectl get all -n game-2048

# Aby usunac calosc:
kubectl delete -f all-in-one.yml


# zawartosc pliku:
---
apiVersion: v1
kind: Namespace 
metadata:
  name: game-2048               # *1v
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: game-2048          # *1^ musi byc jak wyzej
  name: deployment-2048
spec:
  selector:
    matchLabels:
      name: app-2048            # jakimi podami deployment ma sie zaopiekowac (wykrywa wszystkie pody o takiej nazwie)
  replicas: 3
  template:
    metadata:
      labels:
        name: app-2048          # jaka jest nazwa naszych podow
    spec:
      containers:
      - image: k8smaestro/2048  # obraz z dockerHub
        imagePullPolicy: Always # polityka pobierania obrazow na klaster (zawsze pobieraj obraz)
        name: app-2048
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  namespace: game-2048          # *1^
  name: service-2048
spec:
  type: ClusterIP               # ClusterIP: udostepnij aplikacje tylko w obrebie klastra. (serwi otrzymuje unikalny IP tylko w sieci wewnetrznej )
  ports:
  - port: 80                    # jaki port ma byc wystawiony
    targetPort: 80              # port kontenera (containerPort z Deployment, do jakiego porty ma przekierowac ruch)
    protocol: TCP
  selector:
    name: app-2048




#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
MINIKUBE
# Uruchomienie minikube na windowsie.
# Trzeba odpalić CMD w trybie administratora i uruchomic polecenie: (zakładam ze mam zainstalowany hyperV)
minikube start --driver=hyperv

#od tej pory powinny działać polecenia:
minikube start
minikube stop

# aby skasować minikube:
minikube delete





#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
#--------------------------------------------------------------------------------------------------
# Opis, jak wstawić projkt na google cloud
# Film 49 (Kubernetes for the Absolute Beginners - Hands-on)
https://cloud.google.com/free/docs/gcp-free-tier

# 1. menu -> Kuberbetes Engin
# 2. Clusters -> Create cluster
# 3. Wpisujemy indywidualną nazwę, reszta ustawień domyślna.  -> Create  (może to portrwać kilka minut)
# 4. W części "Cluster" pojawi się nowa pozycja z zielonym znaczkiem statusu. -> Connect -> na dole powinna otworzyć się konsola.
# 5. W konsoli powinno pojawić się domyślne polecenie do konfiguracji połaczenia
gcloud container clusters get-credentials example-voting-app --zone us-central1-c --project example-voting-app-283506
# 6. W przykłądzie, projekt jest na githubie
https://github.com/kodekloudhub/example-voting-app
# 7. W konsoli chmury, kopiuje projekt
git clone https://github.com/kodekloudhub/example-voting-app.git
# 8. Po skopiowaniu projektu, wchodzi do folderu projektu, następnei do folderu k8s-specifications z plikami xxx-deploy.yaml i xxx-service.yaml
# 9. W plikach voting-app-service.yaml i result-service.yaml, pozmieniał spec: type: LoadBalancer i usunięty jest "nodePort"
# 10. W konsoli chmury, uruchamiam deploymenty i servisy:
kubectl create -f voting-app-deploy.yaml
kubectl create -f voting-app-service.yaml
    # to samo dla redis, postgres, worker, result
# 11. Po wejściu w zakładkę Kubernetes Engine -> Services & Ingress, 
    # powinienem widzieć uruchomione serwisy i ich statusy
    # Po kliknięciu do Endpoinds, powinno odesłać nas na stronę, gdzie będą widoczne rezultaty

#--------------------------------------------------------------------------------------------------
# Opis, jak wstawić projkt na AWS
# Film 51 (Kubernetes for the Absolute Beginners - Hands-on)
https://docs.aws.amazon.com/eks/latest/userguide/getting-started-console.html
# 1. Po zalogowaniu się, przechodzimy do AWS Managment Console
# 2. Wysukujemy i tworzymy EKS (Elastic Kubernetes Service) 
#   - nadajemy nazwę
#   - W polu Cluster configuration -> Cluster Service Role -> wybieramy EKSRole -> Next
#   - Reszta ustawień domyślna. Kilka razy Next i tworzymy klaster. Może to potrwac kilka minut
# 3. Wchodzimy w EKS > Clusters > nazwa_projektu  i tutaj mamy panel naszego projektu
# 4. W lokalnej konsoli wpisuje polecenie: (chyba w lokalnej)
aws eks --region us-west-2 update-kubeconfig --name example-voting-app
# po wykoaniu komendy 
kubectl get nodes
# powinny pojawic się węzly z opsem: xxx.us-west-2.compute.internal
# reszta poleceń, odbywa sie chyba lokalnie??
# resztę tylko obejżałem...




#--------------------------------------------------------------------------------------------------
  #     #                #                   #      ####
  #     #   #            #                   #      #   #
  #     #       # ###  #####  #   #   ####   #      #   #   ###   #   #
  #     #  ##   ##       #    #   #       #  #      ####   #   #   # #
   #   #    #   #        #    #   #   #####  #      #   #  #   #    #
    # #     #   #        #    #   #  #    #  #   #  #   #  #   #   # #
     #     ###  #         ##   ####   ### #   ###   ####    ###   #   #
#--------------------------------------------------------------------------------------------------
# instalacja VirtualBox na Widowsie - Film 11 7:50 (Kubernetes for the Absolute Beginners - Hands-on)
# Odpaliłem sobie Cygwin64 Terminal:
# Przeprowadziłem instalację ma Windows według: https://kubernetes.io/docs/tasks/tools/install-kubectl-windows/
Install kubectl binary with curl on Windows:
curl -LO "https://dl.k8s.io/release/v1.23.0/bin/windows/amd64/kubectl.exe"

Już mi działa polecenie:
kubectl version --client --output=yaml

Zainstalowałem choco (w PowerShelu), pleceniem:
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))

Zainstalowałem kubernetes-cli:
choco install kubernetes-cli

W nowym oknie PowerShel działa polecenie:
kubectl version --client


Uruchamiam PowerShell w trubie administratora i wpisuje polecenia:
New-Item -Path 'c:\' -Name 'minikube' -ItemType Directory -Force
Invoke-WebRequest -OutFile 'c:\minikube\minikube.exe' -Uri 'https://github.com/kubernetes/minikube/releases/latest/download/minikube-windows-amd64.exe' -UseBasicParsing

$oldPath = [Environment]::GetEnvironmentVariable('Path', [EnvironmentVariableTarget]::Machine)
if ($oldPath.Split(';') -inotcontains 'C:\minikube'){ `
  [Environment]::SetEnvironmentVariable('Path', $('{0};C:\minikube' -f $oldPath), [EnvironmentVariableTarget]::Machine) `
}

Gdy wywołam polecenie:
minikube start --driver=virtualbox
  # Otrzymuje błąd: This computer doesn't have VT-X/AMD-v enabled. Enabling it in the BIOS is mandatory 
Gdy wywołam polecenie:
minikube start --driver=docker
  # Niby jest Done, ale po tym sypie błedami...

Po sprawdzeniu statusu:
minikube status 
  # otrzymałem statusy Runing (czyli dobrze)
  # Jeśli otrzymam Stoped, to trzeba go uruchomić poleceniem  'minikube start' w PowerShelu

Jeśli status jest Runing, działaja polecenia w PowerShel oraz w Cygwin:
kubectl get po -A
  # kilka linijek: kube-system   coredns-64897985d-wx2jf            1/1     Running   1 (2m34s ago)   67m 
kubectl get nodes
  # minikube   Ready    control-plane,master   77m   v1.23.3
kubectl cluster-info
  # CoreDNS is running at https://127.0.0.1:58175/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy




4. Zakładam przykładowa aplikację:
kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.4
Ustawiam dostęp:
kubectl expose deployment hello-minikube --type=NodePort --port=8080

Przy prubie pobrania tunelu, konsola zostaje zawieszona:
minikube service hello-minikube --url
  # http://192.168.49.2:30535   - teoretycznie, pod tym adresem powinienem widzieć coś.

Usunięcie serwisu hello-minikube:
kubectl delete services hello-minikube
Usunięcie deployment hello-minikube:
kubectl delete deployment hello-minikube


Komendy dostepne dla CLUSTER:
minikube pause
minikube unpause
minikube stop
minikube delete --all




kubectl run myNginx --image=nginx  # Stworzy POD z kontenerem nginxa
kubectl get pods -o wide 
  # NAME    READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
  # mtNginx 1/1     Running   0          5m22s   172.17.0.3   minikube   <none>           <none>
kubectl describe pod nginx   # wyświetl szczegóły konkretnego poda













#--------------------------------------------------------------------------------------------------
#                          _             _
#             _         _ ( )           ( )
#   ___ ___  (_)  ___  (_)| |/')  _   _ | |_      __
# /' _ ` _ `\| |/' _ `\| || , <  ( ) ( )| '_`\  /'__`\
# | ( ) ( ) || || ( ) || || |\`\ | (_) || |_) )(  ___/
# (_) (_) (_)(_)(_) (_)(_)(_) (_)`\___/'(_,__/'`\____)
#--------------------------------------------------------------------------------------------------
# Instalacja na ProxMox (nie udana)
# zainstalowałem kubectl według https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/
1. Download the latest release with the command:
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"

2. Validate the binary (optional):
curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check
  kubectl: OK

3. Install kubectl:
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
chmod +x kubectl
mkdir -p ~/.local/bin
mv ./kubectl ~/.local/bin/kubectl

Sprawdzenie, czy dostępna jest wirtualizacja:
grep -E --color 'vmx|svm' /proc/cpuinfo

# Instalacja minikube
1. Installation:
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
    na filmie 11 koles miał inne polecenia:
    curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
    chmod +x minikube
    ls -ld /usr/local/bin/

2. Start your cluster:
minikube start
minikube start --driver=ssh --ssh-ip-address=10.10.10.186

    Na sterfie kursów, kongiguracja nastapiła przez polecenie:
    minikube config set driver docker

    Na moim Windowsie, działa konfiguracja:
    minikube start --driver=hyperv


3. gdy sie zainstaluje, można spawdzic:
minikube status


#-------------------
# W filmie 2, kubectl instalacja (Strefa Kursów Kurs: Kubernetes od podstaw - zarządzanie i automatyzacja kontenerów)
# Koles instaluje kubectl poleceniem:
curl -LO "https://storage.googleapis.com/kubernetes-relase/relase/$(curl -s curl https://storage.googleapis.com/kubernetes-relase/relase/stable.txt)/bin/linux/am64/kubectl"

# następnie, trzeba nadac uprawnienia
chmod +x ./kubectl

# przeneiść plik do sceizki projektu ??
sudo mv ./kubectl /usr/local/bin/kubectl

#Sprawdzenie wersji:
kubectl version --client



# Po zainstalowanieu minikube, mozna do niego wejść poleceniem:
$ minikube ssh

#aby wyjść z tego trybu:
exit

# działa tu polecenie:
docker ps
docker container ls

# aby śledzić jakiś pod, znajac jego adres
watch -n 1 "curl -s 172.17.0.7"


# aby podejżec plik konfguracyjny (w Windowsie). uruchom gitbash w trybie administratora.
# po wspisaniu pwd, powinienem mieć ścieżkę: /c/Users/Humansoft
# po wpisaniu ls -la  powinienem widzieć plik .kube
# Konfiguracja jest w pliku config, który można podejżeć, pn: za pomocą nano lub less:
nano .kube/config


# Po wydaniu polecenia
minikube dashboard
# powinno nam się udac wejsc na stroę:
http://127.0.0.1:46257/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/


# Mariusz!
# Film 3-Kubectl  (sterfa kurów) jest tam informacja, że wymagany jest plik .kube/config
# od 4:30 minuty.
# Tego pliku nam brakuje. On jest gdzieś indziej? Bo bez niego, wuświetla kominikat 
The connection to the server localhost:8080 was refused - did you specify the right host or port?
# Jest to dokładnie w minucie 8:00
# W minucie 10:30 jest, że możemy wymusić korzystanie z innego pliku konfiguracyjnego poleceniem:
export KUBECONFIG=~/.kube/plikKonfiguracyjny 

Filmik 6_7 Statyczne Pody - 
koles mówi coś o ścieżce /etc/kubernetes/manifest
Na naszej maszynie nie ma takiego folderu
Na OVH jest ten folder, ale nie moge wywołać polecenia ls -la /etc/kubernetes/manifests
                                           






